{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多元线性回归\n",
    "## 7.1 引言\n",
    "回归分析是一种通过一组预测变量来预测一个或多个响应变量的统计方法，它也可以用于评估预测变量对响应变量的效果。本章首先讨论预测一个响应变量的多重回归，然后将这个模型推广到预测若干因变量的情况。我们对回归分析的简要讨论重点在以下几个方面:\n",
    "* 模型的假定及其后果\n",
    "* 回归模型的一些不同表达方式\n",
    "* 回归方法在看上去非常不同的场合下的一般应用\n",
    "\n",
    "\n",
    "## 7.2 经典线性回归模型\n",
    "设$z_1,z_2,\\dots, z_r$为r个预测变量，设想它们与一个响应变量Y有关系。例如，对r=4，我们可能有\n",
    "* $Y$ = 住房当前市场价值\n",
    "* $z_1$ = 居住面积(平方英尺)\n",
    "* $z_2$ = 位置(城市区域的指标)\n",
    "* $z_3$ = 去年的评估价值\n",
    "* $z_4$ = 建筑质量(每平方英尺价格)\n",
    "\n",
    "经典线性回归模型，假定Y有一个均值和误差$\\epsilon$合成，其中均值为$z_i$的连续函数，而$\\epsilon$则考虑测量误差和其余未被明确考虑在模型中所产生的效应，在实验中被记录下来或由研究者设定的变量值被视为固定值。误差被看成随机变量，其服从一个假定的分布。\n",
    "$$Y = \\beta_0 + \\beta_1z_1 + \\dots + \\beta_rz_r + \\epsilon \\tag 1$$\n",
    "$$(响应) = [均值(依赖于z_1,\\dots,z_r)] + (误差)$$\n",
    "其中误差项目假定有如下性质:\n",
    "1. $E(\\epsilon)=0$\n",
    "2. $Var(\\epsilon_j)=\\sigma^2(常数)$\n",
    "3. $Cov(\\epsilon_j,\\epsilon_k)=0, j\\neq k$\n",
    "经典归回模型如下\n",
    "$$\\mathop{\\boldsymbol{Y}}_{(n\\times 1)} = \\mathop{\\boldsymbol{Z}}_{(n\\times (r+1))}\\mathop{\\boldsymbol{\\beta}}_{((r+1)\\times 1)} + \\mathop{\\boldsymbol{\\epsilon}}_{(n+1)} \\tag 2$$\n",
    "$$E(\\boldsymbol{\\epsilon})=\\mathop{\\boldsymbol{0}}_{(n\\times n)}, Cov(\\boldsymbol{\\epsilon})=\\sigma^2\\boldsymbol{I}$$\n",
    "其中$\\boldsymbol{\\beta}$和$\\sigma^2$为未知参数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 最小二乘估计\n",
    "回归分析的目标之一是得出一个方程，使研究者可以根据给定的预测变量来预测响应变量的值，这就需要将模型同数据进行拟合，也就是说，我们必须确定与数据相容的**回归系数$\\beta$和误差方差$\\sigma^2$**<br >\n",
    "设$\\boldsymbol{b}$为$\\boldsymbol{\\beta}$的一个尝试值，最小二乘法会选择这样的$\\boldsymbol{b}$，使平方和达到极小:\n",
    "$$S(\\boldsymbol{b})=\\sum_{j=1}^{n}(y_j-b_0-b_1z_{j1}-\\dots - b_rz_{jr})^2 \\tag 3$$\n",
    "$$=(\\boldsymbol{y}-\\boldsymbol{Z}\\boldsymbol{b})^{'}(\\boldsymbol{y}-\\boldsymbol{Z}\\boldsymbol{b})$$\n",
    "由最小二乘法选定的参数$\\boldsymbol{b}$称为$\\boldsymbol{\\beta}$的最小二乘估计。今后将记最小二乘估计为$\\hat{\\boldsymbol{\\beta}}$,以强调是$\\boldsymbol{\\beta}$的估计值。\n",
    "\n",
    "**结论7.1** 设$\\boldsymbol{Z}$有满秩$r+1\\leq n$，则$\\beta$的最小二乘估计为:\n",
    "$$\\hat{\\boldsymbol{\\beta}} = (\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1}\\boldsymbol{Z}^{'}\\boldsymbol{y}$$\n",
    "残差\n",
    "$$\\hat{\\boldsymbol{\\epsilon}}=\\boldsymbol{y}-\\hat{\\boldsymbol{y}} = (\\boldsymbol{I}-\\boldsymbol{H})\\boldsymbol{y}$$\n",
    "其中$\\boldsymbol{H}=\\boldsymbol{Z}(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{'}\\boldsymbol{Z}^{'}\\boldsymbol{y}$\n",
    "    $$残差平方和=\\boldsymbol{y}^{'}\\boldsymbol{y}-\\boldsymbol{y}^{'}\\boldsymbol{Z}\\hat{\\boldsymbol{\\beta}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例子 计算最小二乘估计，残差以及残差平方和\n",
    "#已知\n",
    "import numpy as np\n",
    "\n",
    "Z = np.matrix([[1,1,1,1,1],[0,1,2,3,4]]).T\n",
    "Y = np.matrix([1,4,3,8,9]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZ = Z.T.dot(Z)\n",
    "ZZ_ = np.linalg.inv(ZZ)\n",
    "Zy = Z.T.dot(Y)\n",
    "#拟合参数\n",
    "beta = ZZ_.dot(Zy)\n",
    "#拟合值向量\n",
    "y_hat = Z.dot(beta)\n",
    "#残差\n",
    "e_hat = Y - y_hat\n",
    "#残差平方和\n",
    "e_mse = e_hat.T.dot(e_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平方和分解\n",
    "因为$\\hat{\\boldsymbol{y}}^{'}\\hat{\\boldsymbol{\\epsilon}} = 0$,故总的响应变量平方和$\\boldsymbol{y}^{'}\\boldsymbol{y}=\\sum_{j=1}^{n}y_{i}^2$满足\n",
    "$$\\boldsymbol{y}^{'}\\boldsymbol{y}=(\\hat{\\boldsymbol{y}}+\\boldsymbol{y}-\\hat{\\boldsymbol{y}})^{'}(\\hat{\\boldsymbol{y}}+\\boldsymbol{y}-\\hat{\\boldsymbol{y}}) = (\\hat{\\boldsymbol{y}} + \\hat{\\boldsymbol{\\epsilon}})^{'}(\\hat{\\boldsymbol{y}} + \\hat{\\boldsymbol{\\epsilon}}) = \\hat{\\boldsymbol{y}}^{'}\\hat{\\boldsymbol{y}}+\\hat{\\boldsymbol{\\epsilon}}^{'}\\hat{\\boldsymbol{\\epsilon}} \\tag 7$$\n",
    "由于$\\boldsymbol{Z}$的第一列为1，条件$\\boldsymbol{Z}^{'}\\hat{\\boldsymbol{\\epsilon}}=0$意味着$0=\\boldsymbol{1}^{'}\\hat{\\boldsymbol{\\epsilon}}=\\sum_{j=1}^{n}\\hat{\\boldsymbol{\\epsilon}}_j = \\sum_{j=1}^{n}y_i-\\sum_{j=1}^{n}\\hat{y}_i$,或$\\overline{y}=\\overline{\\hat{y}}$,进行化简得到关于均值平方和的基本分解式。\n",
    "$$\\boldsymbol{y}^{'}\\boldsymbol{y}-n\\overline{y}^2 = \\hat{\\boldsymbol{y}}^{'}\\hat{\\boldsymbol{y}}-n(\\overline{\\hat{y}})^2 + \\hat{\\boldsymbol{\\epsilon}}^{'}\\hat{\\boldsymbol{\\epsilon}}$$\n",
    "或者\n",
    "$$\\sum_{j=1}^{n}(y_j-\\overline{y})^2 = \\sum_{j=1}^{n}(\\hat{y}_j-\\overline{y})^2 + \\sum_{j=1}^{n}\\hat{\\epsilon}^2_j$$\n",
    "$$\\left(\\mathop{均值的总}_{平方和}\\right) = \\left(回归平方和\\right) + \\left(\\mathop{残差(误差)}_{平方和}\\right)$$\n",
    "这个平方和的分解式表明模型拟合的质量可以用**决定系数**来度量，其定义为:\n",
    "$$R^2=1- \\frac{\\sum_{j=1}^{n}\\hat{\\epsilon}_j^2}{\\sum_{j=1}^{n}(y_i-\\overline{y})^2}=\\frac{\\sum_{j=1}^{n}(\\hat{y}_j-\\overline{y})^2}{\\sum_{j=1}^{n}(y_j-\\overline{y})^2}$$\n",
    "$$R^2$$这个量给出$y_j,j=1,\\dots,n$的总变差中由预测变量$z_1, z_2,\\dots, z_r$的解释或所贡献的部分所占比例，若拟合方程通过所有数据点，即对所有j有$\\hat{\\epsilon}_j=0$，此时$R^2$等于1，另一个极端是当$\\hat{\\beta}_0=\\overline{y}$和$\\hat{\\beta}_1=\\hat{\\beta}_2=\\dots=\\hat{\\beta}_r=0$时$R^2$等于0，在这种场合，预测变量$z_1,z_2,\\dots,z_r$对响应变量没有影响。\n",
    "\n",
    "### 最小二乘的几何解释\n",
    "最小二乘法的几何解释能使我们更好的理解这个概念的本质，根据经典的线性回归模型\n",
    "$$响应均值向量=E(\\boldsymbol{Y})=\\boldsymbol{Z}\\boldsymbol{\\beta}=\\beta_0\\begin{bmatrix}1\\\\1\\\\\\vdots\\\\1\\end{bmatrix}+\\beta_1\\begin{bmatrix}z_{11}\\\\z_{21}\\\\ \\vdots \\\\z_{n1}\\end{bmatrix}+\\dots+\\beta_r\\begin{bmatrix}z_{1r}\\\\z_{2r}\\\\ \\vdots \\\\z_{nr}\\end{bmatrix}$$\n",
    "这样，$E(\\boldsymbol{Y})$为$\\boldsymbol{Z}$的列向量的线性组合,当$\\boldsymbol{\\beta}$取所有可能的值时，$\\boldsymbol{Z}\\boldsymbol{\\beta}$张成有所有可能的线性组合构成的模型平面。通常，观测值$\\boldsymbol{y}$不会处于模型平面内，这是随机误差$\\boldsymbol{\\epsilon}$所致，也就是说，$\\boldsymbol{y}$不是$\\boldsymbol{Z}的列向量的线性组合，回顾$\n",
    "$$\\boldsymbol{Y}\\qquad = \\qquad \\boldsymbol{Z\\beta} \\qquad + \\qquad \\boldsymbol{\\epsilon}$$\n",
    "$$\\left(\\mathop{响应}_{向量}\\right) = \\left(\\mathop{模型平面}_{内的向量}\\right) + \\left(\\mathop{误差}_{向量}\\right)$$\n",
    "\n",
    "### 经典最小二乘估计量的抽样性质\n",
    "最小二乘估计量$\\hat{\\beta}$与残差$\\hat{\\epsilon}$的抽样性质在下述结论中详加讨论，\n",
    "**结论 7.2** 在一般线性回归模型下，参数的最小二乘估计量$\\hat{\\boldsymbol{\\beta}}=(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1}\\boldsymbol{Z}^{'}\\boldsymbol{Y}$满足\n",
    "$$E(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\quad 和 \\quad Cov(\\hat{\\boldsymbol{\\beta}})=\\sigma^2(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1}$$\n",
    "残差向量$\\hat{\\boldsymbol{\\epsilon}}$有性质:\n",
    "$$E(\\hat{\\boldsymbol{\\epsilon}}) = \\boldsymbol{0} \\quad 和 \\quad Cov(\\hat{\\boldsymbol{\\epsilon}})=\\sigma^2(\\boldsymbol{I}-\\boldsymbol{Z}(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1}\\boldsymbol{Z}^{'}) = \\sigma^2[\\boldsymbol{I}-\\boldsymbol{H}]$$\n",
    "还有$E(\\hat{\\boldsymbol{\\epsilon}}^{'}\\hat{\\boldsymbol{\\epsilon}})=(n-r-1)\\sigma^2$,故可以定义\n",
    "$$s^2=\\frac{\\hat{\\boldsymbol{\\epsilon}}^{'}\\hat{\\boldsymbol{\\epsilon}}}{n-(r+1)} = \\frac{\\boldsymbol{Y}^{'}[\\boldsymbol{I}-\\boldsymbol{Z}(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1}\\boldsymbol{Z}^{'}]\\boldsymbol{Y}}{n-r-1}=\\frac{\\boldsymbol{Y}^{'}[\\boldsymbol{I}-\\boldsymbol{H}]\\boldsymbol{Y}}{n-r-1}$$\n",
    "我们有\n",
    "$$E(s^2)=\\sigma^2$$\n",
    "\n",
    "**结论7.3** (高斯最小二乘定理) 设$\\boldsymbol{Y}=\\boldsymbol{Z\\beta}+\\epsilon$，其中$E(\\epsilon)=\\boldsymbol{0}， Cov(\\epsilon)=\\sigma^2\\boldsymbol{I}$，且$\\boldsymbol{Z}$有满秩r+1，对任意r+1维常维向量$c$,对于线性函数$c^{'}\\beta$，在所有形如\n",
    "$$a^{'}\\boldsymbol{Y}=a_1Y_1+a_2Y_2+\\dots+a_nY_n$$\n",
    "的线性无偏估计量中，估计量\n",
    "$$\\boldsymbol{c}^{'}\\hat{\\boldsymbol{\\beta}}=c_0\\hat{\\beta}_0+c_1\\hat{\\beta}_1+\\dots+c_r\\hat{\\beta}_r$$\n",
    "的方差最小。**最佳线性无偏估计量**(BLUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4回归模型的推断\n",
    "我们根据经典回归模型以及附加的对误差$\\epsilon$的正态性假定，来描述推断方法。\n",
    "### 关于回归参数的推断\n",
    "在评估回归函数\n",
    "$$E(\\boldsymbol{Y}) = \\beta_0+\\beta_1z_1+\\dots+\\beta_rz_r \\tag {10} $$\n",
    "中特地变量的重要性之前，必须确定$\\hat{\\boldsymbol{\\beta}}$及残差平方和和$\\hat{\\boldsymbol{\\epsilon}}^{'}\\hat{\\boldsymbol{\\epsilon}}$的抽样分布，为此我们将假定误差$\\boldsymbol{\\epsilon}$服从正态分布<br >\n",
    "**结论7.4** 设$\\boldsymbol{Y}=\\boldsymbol{Z\\beta}+\\boldsymbol{\\epsilon}$，其中$Z$有满秩r+1，且$\\epsilon$服从$N_n(\\boldsymbol{0},\\sigma^2\\boldsymbol{I})$分布，此时$\\beta$的极大似然估计量就是最小二乘估计量$\\hat{\\beta}$，进而有\n",
    "$$\\hat{\\boldsymbol{\\beta}}=(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1}\\boldsymbol{Z}^{'}\\boldsymbol{Y}服从N_{r+1}(\\boldsymbol{\\beta},\\sigma^2(\\boldsymbol{Z}^{'}\\boldsymbol{Z})^{-1})$$分布，\n",
    "且$\\hat{\\boldsymbol{\\beta}}$与残差$\\hat{\\boldsymbol{\\epsilon}}=\\boldsymbol{Y}-\\boldsymbol{Z}\\hat{\\boldsymbol{\\beta}}$独立，此外，\n",
    "$$n\\hat{\\sigma}^2=\\hat{\\boldsymbol{\\epsilon}}^{'}\\hat{\\boldsymbol{\\epsilon}}服从\\sigma^2\\chi_{n-r-1}^{2}分布$$\n",
    "其中$\\hat{\\sigma}^2$为$\\sigma^2$的极大似然估计量。<br >\n",
    "**结论7.5** 设$\\boldsymbol{Y}=\\boldsymbol{Z\\beta}+\\boldsymbol{\\epsilon}$,其中$\\boldsymbol{Z}$有满秩r+1，且$\\boldsymbol{\\epsilon}$为$N_n(\\boldsymbol{0},\\sigma^2\\boldsymbol{I})$,此时$\\boldsymbol{\\beta}$的$100(1-\\alpha)\\%$置信域为\n",
    "$$(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}})^{'}\\boldsymbol{Z}^{'}\\boldsymbol{Z}(\\boldsymbol{\\beta}-\\hat{\\boldsymbol{\\beta}}) \\leq (r+1)s^2F_{r+1,n-r-1}(\\alpha)$$\n",
    "其中$F_{r+1,n-r-1}(\\alpha)$为自由度为r+1和n-r-1的F分布的上$100\\alpha$百分点.<br >\n",
    "还有，$\\beta_i, i=1,\\dots,r$的联合置信区间为:\n",
    "$$\\hat{\\beta}_i \\pm \\sqrt{\\hat{Var}(\\hat{\\beta}_i)}\\sqrt{(r+1)F_{r+1,n-r-1}(\\alpha)}, \\quad i=0,1,\\dots, r$$\n",
    "其中$\\hat{Var}(\\hat{\\beta}_i)$为$s^2(\\boldsymbol{Z}^{'}\\boldsymbol{Z}^{-1})$对应于$\\hat{\\beta}_i$的对角元\n",
    "\n",
    "### 回归参数的似然比检验\n",
    "回归分析的部分内容涉及评估特定预测变量对响应变量的影响，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 由估计的回归函数做推断\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
